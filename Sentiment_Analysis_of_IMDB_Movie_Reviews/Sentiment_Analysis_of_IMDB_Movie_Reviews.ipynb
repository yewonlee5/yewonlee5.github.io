{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b378517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import imdb # training:test=1:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b6b7e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data : 25000\n",
      "test data : 25000\n",
      "categories : 2\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = imdb.load_data() # num_words = limit the number of words\n",
    "\n",
    "print('training data : {}'.format(len(X_train)))\n",
    "print('test data : {}'.format(len(X_test)))\n",
    "num_classes = len(set(y_train))\n",
    "print('categories : {}'.format(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a33dcbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frequency for each label:\n",
      "[[    0     1]\n",
      " [12500 12500]]\n"
     ]
    }
   ],
   "source": [
    "unique_elements, counts_elements = np.unique(y_train, return_counts=True)\n",
    "print(\"frequency for each label:\")\n",
    "print(np.asarray((unique_elements, counts_elements)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b10804f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the first review of the training samples : [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "the first label of the training samples : 1\n"
     ]
    }
   ],
   "source": [
    "print('the first review of the training samples :',X_train[0])\n",
    "print('the first label of the training samples :',y_train[0]) # 0 for negative, 1 for positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b756ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index = imdb.get_word_index() # download the word index\n",
    "index_to_word = {}\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value+3] = key # index+3 (rule of the data set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4b10779c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88584"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vocabulary size\n",
    "len(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "238f0e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frequency top 1 : the\n"
     ]
    }
   ],
   "source": [
    "print('frequency top 1 : {}'.format(index_to_word[4])) # 1+3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e47a042c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frequency top 3938 : suited\n"
     ]
    }
   ],
   "source": [
    "print('frequency top 3938 : {}'.format(index_to_word[3941])) # 3938+3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6743440b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert redford's is an amazing actor and now the same being director norman's father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for retail and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also congratulations to the two little boy's that played the part's of norman and paul they were just brilliant children are often left out of the praising list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n"
     ]
    }
   ],
   "source": [
    "# Integer to words for the first sample\n",
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "  index_to_word[index] = token\n",
    "\n",
    "print(' '.join([index_to_word[index] for index in X_train[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "626bba4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the maximum length of the reviews : 2494\n",
      "the average length of the reviews : 238.71364\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the length of each sample\n",
    "reviews_length = [len(review) for review in X_train]\n",
    "\n",
    "print('the maximum length of the reviews : {}'.format(np.max(reviews_length)))\n",
    "print('the average length of the reviews : {}'.format(np.mean(reviews_length)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(reviews_length)\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(reviews_length, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "277f8dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "  count = 0\n",
    "  for sentence in nested_list:\n",
    "    if(len(sentence) <= max_len):\n",
    "        count = count + 1\n",
    "  print('Ratio of reviews with length less than or equal to %s: %s'%(max_len, (count / len(nested_list))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "321b3c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of reviews with length less than or equal to 500: 91.56800000000001\n"
     ]
    }
   ],
   "source": [
    "below_threshold_len(500, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9590dc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "vocab_size = 10000\n",
    "max_len = 500\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5661aabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling 1. Simple Recurrent Neural Network\n",
    "from tensorflow.keras.layers import SimpleRNN, Embedding, Dense\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f7967dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.6450 - acc: 0.6066\n",
      "Epoch 00001: val_acc improved from -inf to 0.77900, saving model to Simple_model.h5\n",
      "313/313 [==============================] - 69s 218ms/step - loss: 0.6450 - acc: 0.6066 - val_loss: 0.4832 - val_acc: 0.7790\n",
      "Epoch 2/15\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.4278 - acc: 0.8127\n",
      "Epoch 00002: val_acc improved from 0.77900 to 0.84060, saving model to Simple_model.h5\n",
      "313/313 [==============================] - 70s 224ms/step - loss: 0.4278 - acc: 0.8127 - val_loss: 0.3934 - val_acc: 0.8406\n",
      "Epoch 3/15\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.4453 - acc: 0.8157\n",
      "Epoch 00003: val_acc did not improve from 0.84060\n",
      "313/313 [==============================] - 67s 214ms/step - loss: 0.4453 - acc: 0.8157 - val_loss: 0.4509 - val_acc: 0.7920\n",
      "Epoch 4/15\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.3381 - acc: 0.8624\n",
      "Epoch 00004: val_acc did not improve from 0.84060\n",
      "313/313 [==============================] - 68s 217ms/step - loss: 0.3381 - acc: 0.8624 - val_loss: 0.4687 - val_acc: 0.7736\n",
      "Epoch 5/15\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.3149 - acc: 0.8739\n",
      "Epoch 00005: val_acc did not improve from 0.84060\n",
      "313/313 [==============================] - 67s 213ms/step - loss: 0.3149 - acc: 0.8739 - val_loss: 0.4126 - val_acc: 0.8172\n",
      "Epoch 6/15\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.3212 - acc: 0.8762\n",
      "Epoch 00006: val_acc did not improve from 0.84060\n",
      "313/313 [==============================] - 67s 214ms/step - loss: 0.3212 - acc: 0.8762 - val_loss: 0.4514 - val_acc: 0.7876\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 100 # embedding dimension\n",
    "hidden_units = 128 # number of hidden neurons\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim))\n",
    "model.add(SimpleRNN(hidden_units))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('Simple_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(X_train, y_train, epochs=15, callbacks=[es, mc], batch_size=64, validation_split=0.2)\n",
    "# use different validating data from evaluating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d333f947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 30s 38ms/step - loss: 0.4477 - acc: 0.7965\n",
      "\n",
      " test accuracy: 0.7965\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "Simple_loaded_model = load_model('Simple_model.h5')\n",
    "print(\"\\n test accuracy: %.4f\" % (model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48c25f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling 2. Gated Recurrent Unit\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU, Embedding # Gated recurrent units\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "634cf2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.4890 - acc: 0.7574\n",
      "Epoch 00001: val_acc improved from -inf to 0.83580, saving model to GRU_model.h5\n",
      "313/313 [==============================] - 215s 675ms/step - loss: 0.4890 - acc: 0.7574 - val_loss: 0.3777 - val_acc: 0.8358\n",
      "Epoch 2/15\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.3120 - acc: 0.8786\n",
      "Epoch 00002: val_acc improved from 0.83580 to 0.85700, saving model to GRU_model.h5\n",
      "313/313 [==============================] - 228s 726ms/step - loss: 0.3120 - acc: 0.8786 - val_loss: 0.3483 - val_acc: 0.8570\n",
      "Epoch 3/15\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.2556 - acc: 0.9039\n",
      "Epoch 00003: val_acc improved from 0.85700 to 0.87740, saving model to GRU_model.h5\n",
      "313/313 [==============================] - 223s 714ms/step - loss: 0.2556 - acc: 0.9039 - val_loss: 0.3463 - val_acc: 0.8774\n",
      "Epoch 4/15\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.2022 - acc: 0.9247\n",
      "Epoch 00004: val_acc improved from 0.87740 to 0.89580, saving model to GRU_model.h5\n",
      "313/313 [==============================] - 206s 658ms/step - loss: 0.2022 - acc: 0.9247 - val_loss: 0.2704 - val_acc: 0.8958\n",
      "Epoch 5/15\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.1609 - acc: 0.9410\n",
      "Epoch 00005: val_acc did not improve from 0.89580\n",
      "313/313 [==============================] - 209s 668ms/step - loss: 0.1609 - acc: 0.9410 - val_loss: 0.2775 - val_acc: 0.8878\n",
      "Epoch 6/15\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.1206 - acc: 0.9567\n",
      "Epoch 00006: val_acc did not improve from 0.89580\n",
      "313/313 [==============================] - 212s 678ms/step - loss: 0.1206 - acc: 0.9567 - val_loss: 0.3726 - val_acc: 0.8848\n",
      "Epoch 7/15\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0916 - acc: 0.9688\n",
      "Epoch 00007: val_acc did not improve from 0.89580\n",
      "313/313 [==============================] - 222s 709ms/step - loss: 0.0916 - acc: 0.9688 - val_loss: 0.3148 - val_acc: 0.8790\n",
      "Epoch 8/15\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0708 - acc: 0.9765\n",
      "Epoch 00008: val_acc did not improve from 0.89580\n",
      "313/313 [==============================] - 234s 748ms/step - loss: 0.0708 - acc: 0.9765 - val_loss: 0.3556 - val_acc: 0.8878\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 100 # embedding dimension\n",
    "hidden_units = 128 # number of hidden neurons\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim))\n",
    "model.add(GRU(hidden_units))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('GRU_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(X_train, y_train, epochs=15, callbacks=[es, mc], batch_size=64, validation_split=0.2)\n",
    "# use different validating data from evaluating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cb2f905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 68s 86ms/step - loss: 0.2937 - acc: 0.8830\n",
      "\n",
      " test accuracy: 0.8830\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "GRU_loaded_model = load_model('GRU_model.h5')\n",
    "print(\"\\n test accuracy: %.4f\" % (GRU_loaded_model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e62a354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling 3. 1D Convolution Neural Network\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dropout, Conv1D, GlobalMaxPooling1D, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "257f25b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.4339 - acc: 0.7788\n",
      "Epoch 00001: val_acc improved from -inf to 0.88040, saving model to CNN_model.h5\n",
      "625/625 [==============================] - 71s 113ms/step - loss: 0.4339 - acc: 0.7788 - val_loss: 0.2889 - val_acc: 0.8804\n",
      "Epoch 2/20\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2204 - acc: 0.9131\n",
      "Epoch 00002: val_acc improved from 0.88040 to 0.89080, saving model to CNN_model.h5\n",
      "625/625 [==============================] - 63s 101ms/step - loss: 0.2204 - acc: 0.9131 - val_loss: 0.2626 - val_acc: 0.8908\n",
      "Epoch 3/20\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1213 - acc: 0.9575\n",
      "Epoch 00003: val_acc did not improve from 0.89080\n",
      "625/625 [==============================] - 63s 101ms/step - loss: 0.1213 - acc: 0.9575 - val_loss: 0.2898 - val_acc: 0.8888\n",
      "Epoch 4/20\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0575 - acc: 0.9801\n",
      "Epoch 00004: val_acc did not improve from 0.89080\n",
      "625/625 [==============================] - 64s 102ms/step - loss: 0.0575 - acc: 0.9801 - val_loss: 0.3325 - val_acc: 0.8898\n",
      "Epoch 5/20\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0306 - acc: 0.9894\n",
      "Epoch 00005: val_acc did not improve from 0.89080\n",
      "625/625 [==============================] - 67s 108ms/step - loss: 0.0306 - acc: 0.9894 - val_loss: 0.3765 - val_acc: 0.8902\n",
      "Epoch 00005: early stopping\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 128 # embedding dimension\n",
    "dropout_ratio = 0.3 # dropout ratio\n",
    "num_filters = 128 # number of filters(kernels)\n",
    "kernel_size = 3 # size of filters(kernels)\n",
    "hidden_units = 128 # number of hidden neurons\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim))\n",
    "model.add(Dropout(dropout_ratio))\n",
    "model.add(Conv1D(num_filters, kernel_size, padding='valid', activation='relu'))\n",
    "model.add(GlobalMaxPooling1D()) # max pooling\n",
    "model.add(Dense(hidden_units, activation='relu'))\n",
    "model.add(Dropout(dropout_ratio))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
    "mc = ModelCheckpoint('CNN_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(X_train, y_train, epochs=20, callbacks=[es, mc], validation_split=0.2)\n",
    "# use different validating data from evaluating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a948260e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 11s 13ms/step - loss: 0.2672 - acc: 0.8885\n",
      "\n",
      " test accuracy: 0.8885\n"
     ]
    }
   ],
   "source": [
    "CNN_loaded_model = load_model('CNN_model.h5')\n",
    "print(\"\\n test accuracy: %.4f\" % (CNN_loaded_model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c67d33e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling 4. Multi-Kernel Convolution Neural Network\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding, Dropout, Conv1D, GlobalMaxPooling1D, Dense, Input, Flatten, Concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6273fa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 128 # embedding dimension\n",
    "dropout_ratio = (0.3, 0.5) # dropout ratio\n",
    "num_filters = 128 # number of filters(kernels)\n",
    "hidden_units = 128 # number of hidden neurons\n",
    "\n",
    "# Define model input and embedding layer\n",
    "model_input = Input(shape = (max_len,))\n",
    "z = Embedding(vocab_size, embedding_dim, input_length = max_len, name=\"embedding\")(model_input)\n",
    "z = Dropout(dropout_ratio[0])(z) # dropout ratio = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f19e6cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_blocks = []\n",
    "\n",
    "for sz in [3, 4, 5]: # kernel size = 3, 4, 5\n",
    "    conv = Conv1D(filters = num_filters, # 128 for each kernel\n",
    "                         kernel_size = sz,\n",
    "                         padding = \"valid\",\n",
    "                         activation = \"relu\",\n",
    "                         strides = 1)(z) # strides = 1\n",
    "    conv = GlobalMaxPooling1D()(conv) # max pooling\n",
    "    conv_blocks.append(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b1bbfc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.86340, saving model to Multi_CNN_model.h5\n",
      "313/313 - 159s - loss: 0.5237 - acc: 0.7117 - val_loss: 0.3261 - val_acc: 0.8634 - 159s/epoch - 509ms/step\n",
      "Epoch 2/20\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.86340 to 0.88680, saving model to Multi_CNN_model.h5\n",
      "313/313 - 151s - loss: 0.2985 - acc: 0.8749 - val_loss: 0.2678 - val_acc: 0.8868 - 151s/epoch - 482ms/step\n",
      "Epoch 3/20\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.88680 to 0.89820, saving model to Multi_CNN_model.h5\n",
      "313/313 - 157s - loss: 0.2014 - acc: 0.9223 - val_loss: 0.2626 - val_acc: 0.8982 - 157s/epoch - 501ms/step\n",
      "Epoch 4/20\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.89820\n",
      "313/313 - 162s - loss: 0.1406 - acc: 0.9474 - val_loss: 0.3035 - val_acc: 0.8902 - 162s/epoch - 517ms/step\n",
      "Epoch 5/20\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.89820\n",
      "313/313 - 162s - loss: 0.0906 - acc: 0.9668 - val_loss: 0.3480 - val_acc: 0.8862 - 162s/epoch - 519ms/step\n",
      "Epoch 6/20\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.89820\n",
      "313/313 - 155s - loss: 0.0683 - acc: 0.9764 - val_loss: 0.3875 - val_acc: 0.8854 - 155s/epoch - 496ms/step\n",
      "Epoch 7/20\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.89820\n",
      "313/313 - 158s - loss: 0.0470 - acc: 0.9830 - val_loss: 0.5046 - val_acc: 0.8782 - 158s/epoch - 505ms/step\n",
      "Epoch 00007: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d5870a5e20>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the results after max pooling and send it to hidden layers\n",
    "z = Concatenate()(conv_blocks) if len(conv_blocks) > 1 else conv_blocks[0]\n",
    "z = Dropout(dropout_ratio[1])(z) # dropout ratio = 0.5\n",
    "z = Dense(hidden_units, activation=\"relu\")(z)\n",
    "model_output = Dense(1, activation=\"sigmoid\")(z)\n",
    "\n",
    "model = Model(model_input, model_output)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('Multi_CNN_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=20, validation_split=0.2, verbose=2, callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9fcca9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 37s 47ms/step - loss: 0.2841 - acc: 0.8836\n",
      "\n",
      " test accuracy: 0.8836\n"
     ]
    }
   ],
   "source": [
    "Multi_CNN_loaded_model = load_model('Multi_CNN_model.h5')\n",
    "print(\"\\n test accuracy: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b6b6ef6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model using 1D CNN shows the highest accuracy\n",
    "# Let's make a make a Sentiment Predictor with this model\n",
    "\n",
    "import re\n",
    "\n",
    "def sentiment_predict(new_sentence):\n",
    "  new_sentence = re.sub('[^0-9a-zA-Z ]', '', new_sentence).lower() # Remain only alphabets and numbers, Uppercase to lowercase\n",
    "  encoded = []\n",
    "\n",
    "  for word in new_sentence.split(): # Tokenization\n",
    "    try :\n",
    "      if word_to_index[word] <= 10000: # Vocabulary size <= 10000\n",
    "        encoded.append(word_to_index[word]+3)\n",
    "      else:\n",
    "        encoded.append(2) # If vocabulary > 10000, move to <unk> token\n",
    "    except KeyError:\n",
    "      encoded.append(2) # OOV (Out of Vocabulary) to <unk> token\n",
    "\n",
    "  pad_sequence = pad_sequences([encoded], maxlen=max_len) # Padding\n",
    "  score = float(CNN_loaded_model.predict(pad_sequence)) # Prediction with the model\n",
    "\n",
    "  if(score > 0.5): # Threshold = 0.5\n",
    "    print(\"Positive review with the probability of {:.2f}%\".format(score * 100))\n",
    "  else:\n",
    "    print(\"Negative review with the probability of {:.2f}%\".format((1 - score) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0d53e894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative review with the probability of 99.68%\n"
     ]
    }
   ],
   "source": [
    "test_input1 = \"The story is boring and dull, I love Mads, but Johnny was born for this role. No Johnny, no more great scores for you. WB, you deserve only 1s for all of your movies. Trying to be as successful as Marvel/Disney, but failing miserably. Worst end of all the HP movies.\"\n",
    "\n",
    "sentiment_predict(test_input1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bf010dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive review with the probability of 99.65%\n"
     ]
    }
   ],
   "source": [
    "test_input2 = \"Even though it still has a reasonably messy narrative, Fantastic Beasts: The Secrets of Dumbledore is a significant improvement over it's disappointing predecessor that actually remembers to be fun and emotionally satisfying with genuinely magical moments. Eddie Redmayne still has the adorably awkward charm and likeability that make him a consistently great lead. Mads Mikkelsen is definitely the best Grindelwald with a more subtle and restrained evil presence. Jude Law is once again an incredible Dumbledore and Dan Fogler is still a really funny scene stealer. Jessica Williams is an amazing new addition with endless charisma and is instantly likeable. David Yates' direction is really good despite having done so many already, still delivering inventive set pieces and great fights. The CG is mostly impressive if a little overused. The music by James Newton Howard is excellent, adding to the overall atmosphere with effective callbacks and heartwarming whimsy.\"\n",
    "\n",
    "sentiment_predict(test_input2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py39] *",
   "language": "python",
   "name": "conda-env-py39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
